<div align="center">
<img width="1200" height="475" alt="GHBanner" src="https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6" />
</div>

# ğŸ¤Ÿ AI Sign Language Translator
### Real-Time Communication Bridge for Deaf & Hearing Communities


---



**Problem:** 70 million deaf people worldwide struggle to communicate with hearing individuals  
**Solution:** AI system that translates sign language to speech/text and speech to sign language  
**Tech:** Google Gemini Vision AI â€¢ Web Speech API â€¢ Real-time video processing  
**Impact:** Enables instant two-way communication between deaf and hearing communities  

---

## ğŸ¯ What It Does

```
Sign Language Gestures â†’ AI Vision Analysis â†’ Speech/Text Output
Speech/Text Input â†’ AI Processing â†’ Sign Language Animation
```

**Real Example:** User signs "Hello, how are you?" â†’ System speaks it aloud and displays text

---

## ğŸ“Š Core Features

| Feature | Description |
|---------|-------------|
| ğŸ¥ **Sign to Speech** | Translates sign language gestures into spoken words |
| ğŸ“ **Sign to Text** | Converts signs to written text on screen |
| ğŸ—£ï¸ **Speech to Sign** | Translates spoken language into sign language animations |
| âš¡ **Real-Time** | Processes video feed with minimal latency |
| ğŸŒ **Multi-Language** | Supports ASL, BSL, and other sign languages |
| ğŸ“± **Camera-Based** | Works with standard webcam or phone camera |

---

## ğŸ› ï¸ Tech Stack

**AI/ML:** Google Gemini Vision AI â€¢ Computer Vision  
**Frontend:** React â€¢ Web Speech API â€¢ Video Processing  
**Backend:** Node.js â€¢ WebRTC  
**Deployment:** Google AI Studio â€¢ Local deployment ready  

---

## ğŸš€ Quick Start

### Run Locally:

```bash
# Clone the repository
git clone https://github.com/yourusername/sign-language-translator.git
cd sign-language-translator

# Install dependencies
npm install

# Start the app
npm start

# Open http://localhost:3000
```

### Try in AI Studio:

âš¡ **Open in Google AI Studio:** [Launch App](https://ai.studio/apps/drive/18WwjCwZbUikMn900l0oD7HFd-vqK1YHw)

---

## ğŸ’¡ How It Works

### Sign Language to Speech/Text:
1. User performs sign language gestures in front of camera
2. AI analyzes video frames to recognize gestures
3. System converts recognized signs to text
4. Text is spoken aloud using text-to-speech
5. Text displayed on screen simultaneously

### Speech/Text to Sign Language:
1. User speaks into microphone or types text
2. Speech-to-text converts audio to text
3. AI maps text to corresponding sign language gestures
4. System displays sign animations or descriptions
5. Real-time visual feedback provided

---

## ğŸ¯ Use Cases

âœ… **Conversations** - Enable real-time dialogue between deaf and hearing individuals  
âœ… **Education** - Learn sign language with instant feedback  
âœ… **Accessibility** - Make public spaces more inclusive  
âœ… **Emergency Services** - Critical communication in urgent situations  
âœ… **Customer Service** - Better serve deaf customers  
âœ… **Video Calls** - Add sign language translation to video meetings  

---

## ğŸ“ˆ Impact Potential

**70 Million Deaf People Worldwide:**
- 466 million people with hearing loss globally (WHO)
- Communication barriers in employment, healthcare, education
- Limited access to real-time interpretation services
- Existing solutions expensive and not always available

**This Tool Provides:**
- Free, accessible communication bridge
- Instant translation without human interpreter
- Privacy (no third-party interpreter needed)
- Available 24/7 on any device with camera

---

## ğŸ—ï¸ Project Structure

```
sign-language-translator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ VideoCapture.jsx
â”‚   â”‚   â”œâ”€â”€ SignDetector.jsx
â”‚   â”‚   â”œâ”€â”€ SpeechOutput.jsx
â”‚   â”‚   â””â”€â”€ TextDisplay.jsx
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ geminiAPI.js
â”‚   â”‚   â”œâ”€â”€ speechAPI.js
â”‚   â”‚   â””â”€â”€ videoProcessor.js
â”‚   â””â”€â”€ App.jsx
â”œâ”€â”€ public/
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration

### Environment Variables:
```bash
GEMINI_API_KEY=your_gemini_api_key
SPEECH_API_KEY=your_speech_api_key (if needed)
```

### Camera Permissions:
- App requires webcam access for sign language detection
- Microphone access for speech-to-sign translation

---

## ğŸ¨ Key Features in Detail

### 1. **Real-Time Sign Detection**
- Captures video frames at 30fps
- Analyzes hand positions, movements, facial expressions
- Recognizes individual signs and continuous signing

### 2. **Text-to-Speech Output**
- Natural-sounding voice synthesis
- Adjustable speech rate and volume
- Multiple voice options

### 3. **Speech-to-Text Input**
- Accurate voice recognition
- Works with different accents
- Real-time transcription

### 4. **Sign Language Display**
- Visual representation of signs
- Smooth animations
- Clear instructional feedback

---

## ğŸš§ Current Limitations

- Sign language vocabulary coverage varies
- Lighting conditions affect detection accuracy
- Requires clear camera view of hands and face
- Internet connection needed for AI processing
- Best performance with standard webcam or phone camera

---

## ğŸ—ºï¸ Roadmap

**Current Version:**
- âœ… Basic sign-to-text translation
- âœ… Text-to-speech output
- âœ… Speech-to-text input
- âœ… Real-time video processing


 

---

## ğŸ¤ Contributing

Contributions welcome! This project aims to improve accessibility for deaf and hard-of-hearing communities.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

MIT License - Open source for accessibility

---

## ğŸ™ Acknowledgments

- **Deaf community** - Feedback and testing
- **Google** - Gemini Vision AI API
- **Sign language educators** - Technical guidance
- **Accessibility advocates** - Project direction

---

<div align="center">

### ğŸ’¼ Available for collaboration and feedback

**Bridging communication gaps, one sign at a time.**

[ğŸ“§ Contact](mailto:yourname@email.com) â€¢ [ğŸ’» GitHub](https://github.com/yourusername) â€¢ [ğŸ’¬ LinkedIn](https://linkedin.com/in/yourname)

</div>

1. Install dependencies:<img width="643" height="332" alt="Screenshot 2025-11-13 233232" src="https://github.com/user-attachments/assets/e1eef6b1-a522-4b61-8c06-0838b0e3ec2b" />


https://github.com/user-attachments/assets/539d5c85-bff9-4b14-a055-24f695a2c89e


`
